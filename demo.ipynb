{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import utils, draw\n",
    "from models import net3d\n",
    "from data.dataloader import Dataset\n",
    "from data.augments import Reshape, ToTensor\n",
    "from infer import infer \n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Session name\n",
    "session_name = datetime.now().strftime('%b%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session path\n",
    "root_path = os.path.abspath(\".\")\n",
    "sessions_path = os.path.join(root_path, \"sessions\")\n",
    "session_name = '_'.join((\"session\", session_name,'test'))\n",
    "session_path = os.path.join(sessions_path, session_name)\n",
    "picture_path = os.path.join(session_path, \"picture\")\n",
    "bin_path = os.path.join(session_path, \"bin\")\n",
    "\n",
    "utils.makeDir(session_path)\n",
    "utils.makeDir(picture_path)\n",
    "utils.makeDir(bin_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n1, n2, n3, n_channels = 256, 256, 128, 1\n",
    "dataset_name = \"syn\"\n",
    "data_root_dir = os.path.join(root_path, \"datasets\", dataset_name)\n",
    "data_path = os.path.join(data_root_dir, \"seis\")\n",
    "if not os.path.isdir(data_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset path not found: {data_path}. Available under datasets/: {os.listdir(os.path.join(root_path, 'datasets'))}\"\n",
    "    )\n",
    "data_list = os.listdir(data_path)\n",
    "list_IDs = utils.sort_list_IDs(data_list)\n",
    "only_load_input = True\n",
    "\n",
    "# Dataset\n",
    "dataset = Dataset(root_dir=data_root_dir, list_IDs=list_IDs,\n",
    "                  transform=transforms.Compose([\n",
    "                      Reshape((n1, n2, n3, n_channels)),\n",
    "                      ToTensor(),\n",
    "                  ]),\n",
    "                  only_load_input=only_load_input)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "dataloader_val = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No trained model file found (.pth/.pt).\nNext step: run training first (sh train.sh) or place a pretrained model at\n  checkpoints/trained_RGTNet_parameters.pth\nor checkpoints/trained_RGTNet.pth\nSearched 2 candidate paths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m trained_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m candidate_paths \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(p)), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trained_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trained model file found (.pth/.pt).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext step: run training first (sh train.sh) or place a pretrained model at\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  checkpoints/trained_RGTNet_parameters.pth\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor checkpoints/trained_RGTNet.pth\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(candidate_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m candidate paths.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing model checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrained_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m param_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trained_model_path\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No trained model file found (.pth/.pt).\nNext step: run training first (sh train.sh) or place a pretrained model at\n  checkpoints/trained_RGTNet_parameters.pth\nor checkpoints/trained_RGTNet.pth\nSearched 2 candidate paths."
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "param_model = {}\n",
    "param_model['input_channels'] = 1\n",
    "param_model['encoder_channels'] = 512\n",
    "param_model['decoder_channels'] = 16\n",
    "\n",
    "# Candidate checkpoints (priority order)\n",
    "candidate_paths = [\n",
    "    os.path.join(root_path, \"checkpoints\", \"trained_RGTNet_parameters.pth\"),\n",
    "    os.path.join(root_path, \"checkpoints\", \"trained_RGTNet.pth\"),\n",
    "]\n",
    "\n",
    "# Also search any saved checkpoints under sessions/*/checkpoint/*.pth\n",
    "sessions_dir = os.path.join(root_path, \"sessions\")\n",
    "if os.path.isdir(sessions_dir):\n",
    "    for session_name_dir in sorted(os.listdir(sessions_dir)):\n",
    "        ckpt_dir = os.path.join(sessions_dir, session_name_dir, \"checkpoint\")\n",
    "        if os.path.isdir(ckpt_dir):\n",
    "            for filename in sorted(os.listdir(ckpt_dir)):\n",
    "                if filename.endswith(\".pth\") or filename.endswith(\".pt\"):\n",
    "                    candidate_paths.append(os.path.join(ckpt_dir, filename))\n",
    "\n",
    "trained_model_path = next((p for p in candidate_paths if os.path.isfile(p)), None)\n",
    "if trained_model_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No trained model file found (.pth/.pt).\\n\"\n",
    "        \"Next step: run training first (sh train.sh) or place a pretrained model at\\n\"\n",
    "        \"  checkpoints/trained_RGTNet_parameters.pth\\n\"\n",
    "        \"or checkpoints/trained_RGTNet.pth\\n\"\n",
    "        f\"Searched {len(candidate_paths)} candidate paths.\"\n",
    "    )\n",
    "\n",
    "print(f\"Using model checkpoint: {trained_model_path}\")\n",
    "param_model['trained_model_path'] = trained_model_path\n",
    "model = net3d.model(param_model)\n",
    "\n",
    "# Load trained model parameters\n",
    "if use_cuda:\n",
    "    model.load_state_dict(torch.load(param_model['trained_model_path']))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(param_model['trained_model_path'], map_location='cpu'))\n",
    "\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "# Send CNN model to GPU or CPU\n",
    "if use_cuda:\n",
    "    num_GPU = torch.cuda.device_count()\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(num_GPU)).to(device)\n",
    "else:\n",
    "    print(f\"CPU mode\")\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "pared_sample_list = infer(model, dataloader, only_load_input, bin_path, picture_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = len(pared_sample_list)\n",
    "random_idex_sample = np.random.randint(num_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seis = pared_sample_list[random_idex_sample]['seis']\n",
    "draw.draw_slice(seis, x_slice=30, y_slice=30, z_slice=120, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = utils.min_max_norm(pared_sample_list[random_idex_sample]['pred_rgt'])\n",
    "draw.draw_slice_surf(seis, volume2=pred, x_slice=30, y_slice=30, z_slice=120, \n",
    "                     cmap='gray', isofs=[0.25,0.5,0.75])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
