{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e3763d",
   "metadata": {},
   "source": [
    "# Train Joint RGT + Fault Model (Independent Pipeline)\n",
    "\n",
    "This notebook trains a multitask model using:\n",
    "- seismic input (`seis`)\n",
    "- RGT labels (`rgt`)\n",
    "- fault labels (`fault`)\n",
    "\n",
    "It is independent from the RGT-only training notebook and keeps both workflows separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe8783",
   "metadata": {},
   "source": [
    "## 1) Environment and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb57933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import net3d\n",
    "from lossf.loss import mse3DLoss, ssim3DLoss\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "DATA_ROOT = ROOT / \"datasets\" / \"syn\"\n",
    "SEIS_DIR = DATA_ROOT / \"seis\"\n",
    "RGT_DIR = DATA_ROOT / \"rgt\"\n",
    "FAULT_DIR = DATA_ROOT / \"fault\"\n",
    "\n",
    "SESSION_NAME = f\"rgt_fault_{datetime.now().strftime('%b%d_%H%M%S')}_Train\"\n",
    "SESSION_PATH = ROOT / \"sessions\" / SESSION_NAME\n",
    "CKPT_PATH = SESSION_PATH / \"checkpoint\"\n",
    "HISTORY_PATH = SESSION_PATH / \"history\"\n",
    "FIG_PATH = SESSION_PATH / \"picture\"\n",
    "for p in [SESSION_PATH, CKPT_PATH, HISTORY_PATH, FIG_PATH]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"shape\": (256, 256, 128),\n",
    "    \"batch_size\": 1,\n",
    "    \"epochs\": 200,\n",
    "    \"lr\": 8e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 2,\n",
    "    \"num_workers\": 2,\n",
    "    \"encoder_channels\": 512,\n",
    "    \"decoder_channels\": 16,\n",
    "    \"pin_memory\": True,\n",
    "    \"mixed_precision\": True,\n",
    "    \"grad_clip\": None,\n",
    "    \"loss_rgt\": \"SSIM\",    # SSIM or MSE\n",
    "    \"lambda_rgt\": 1.0,\n",
    "    \"lambda_fault\": 1.0,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"max_samples\": None,\n",
    "    \"use_augmentation\": True,\n",
    "    \"pretrained_rgt_ckpt\": None,\n",
    "    \"save_every\": 5,\n",
    "}\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print(f\"[GPU MODE] Using {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[CPU MODE] CUDA not available\")\n",
    "\n",
    "def resolve_pretrained_rgt_ckpt(explicit_path):\n",
    "    if explicit_path:\n",
    "        p = Path(explicit_path)\n",
    "        return p if p.is_file() else None\n",
    "\n",
    "    candidates = []\n",
    "    candidates += sorted((ROOT / \"sessions\").glob(\"*_Train/checkpoint/best_rgt_only.pth\"))\n",
    "    candidates += sorted((ROOT / \"checkpoints\").glob(\"*.pth\"))\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    return max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "\n",
    "PRETRAINED_RGT_CKPT = resolve_pretrained_rgt_ckpt(CFG[\"pretrained_rgt_ckpt\"])\n",
    "if PRETRAINED_RGT_CKPT is not None:\n",
    "    print(f\"Using pretrained RGT checkpoint: {PRETRAINED_RGT_CKPT}\")\n",
    "else:\n",
    "    print(\"No pretrained RGT checkpoint found. Joint model will train from scratch.\")\n",
    "\n",
    "print(\"Session:\", SESSION_PATH)\n",
    "print(json.dumps(CFG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bff24",
   "metadata": {},
   "source": [
    "## 2) Load and Inspect Seis + RGT + Fault Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be74d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SEIS_DIR.exists(), f\"Missing: {SEIS_DIR}\"\n",
    "assert RGT_DIR.exists(), f\"Missing: {RGT_DIR}\"\n",
    "assert FAULT_DIR.exists(), f\"Missing: {FAULT_DIR}\"\n",
    "\n",
    "seis_ids = {f.name for f in SEIS_DIR.iterdir() if f.is_file()}\n",
    "rgt_ids = {f.name for f in RGT_DIR.iterdir() if f.is_file()}\n",
    "fault_ids = {f.name for f in FAULT_DIR.iterdir() if f.is_file()}\n",
    "\n",
    "ids = sorted(list(seis_ids & rgt_ids & fault_ids))\n",
    "print(f\"Seis: {len(seis_ids)}, RGT: {len(rgt_ids)}, Fault: {len(fault_ids)}\")\n",
    "print(f\"Matched triples: {len(ids)}\")\n",
    "\n",
    "if CFG[\"max_samples\"] is not None:\n",
    "    ids = ids[:CFG[\"max_samples\"]]\n",
    "print(\"Using samples:\", len(ids))\n",
    "\n",
    "n1, n2, n3 = CFG[\"shape\"]\n",
    "rid = random.choice(ids)\n",
    "seis = np.fromfile(SEIS_DIR / rid, dtype=np.float32).reshape(n1, n2, n3)\n",
    "rgt = np.fromfile(RGT_DIR / rid, dtype=np.float32).reshape(n1, n2, n3)\n",
    "fault = np.fromfile(FAULT_DIR / rid, dtype=np.float32).reshape(n1, n2, n3)\n",
    "fault = (fault > 0.5).astype(np.float32)\n",
    "\n",
    "print(\"Example sample:\", rid)\n",
    "print(\"Fault positive ratio:\", float(fault.mean()))\n",
    "\n",
    "mid_i, mid_x, mid_t = n1 // 2, n2 // 2, n3 // 2\n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 10))\n",
    "ax[0, 0].imshow(seis[mid_i], cmap=\"gray\", aspect=\"auto\"); ax[0, 0].set_title(\"Seis inline\")\n",
    "ax[0, 1].imshow(seis[:, mid_x, :], cmap=\"gray\", aspect=\"auto\"); ax[0, 1].set_title(\"Seis xline\")\n",
    "ax[0, 2].imshow(seis[:, :, mid_t], cmap=\"gray\", aspect=\"auto\"); ax[0, 2].set_title(\"Seis time\")\n",
    "ax[1, 0].imshow(rgt[mid_i], cmap=\"jet\", aspect=\"auto\"); ax[1, 0].set_title(\"RGT inline\")\n",
    "ax[1, 1].imshow(rgt[:, mid_x, :], cmap=\"jet\", aspect=\"auto\"); ax[1, 1].set_title(\"RGT xline\")\n",
    "ax[1, 2].imshow(rgt[:, :, mid_t], cmap=\"jet\", aspect=\"auto\"); ax[1, 2].set_title(\"RGT time\")\n",
    "ax[2, 0].imshow(fault[mid_i], cmap=\"magma\", aspect=\"auto\"); ax[2, 0].set_title(\"Fault inline\")\n",
    "ax[2, 1].imshow(fault[:, mid_x, :], cmap=\"magma\", aspect=\"auto\"); ax[2, 1].set_title(\"Fault xline\")\n",
    "ax[2, 2].imshow(fault[:, :, mid_t], cmap=\"magma\", aspect=\"auto\"); ax[2, 2].set_title(\"Fault time\")\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7087ea",
   "metadata": {},
   "source": [
    "## 3) Build Dataset and DataLoader Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afafa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RgtFaultDataset(TorchDataset):\n",
    "    def __init__(self, root_dir: Path, ids_list, shape, augment=False):\n",
    "        self.root = root_dir\n",
    "        self.ids = ids_list\n",
    "        self.shape = shape\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def _read_vol(self, folder: str, file_id: str):\n",
    "        arr = np.fromfile(self.root / folder / file_id, dtype=np.float32)\n",
    "        arr = arr.reshape(self.shape)\n",
    "        return arr\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_id = self.ids[index]\n",
    "        seis = self._read_vol(\"seis\", file_id)\n",
    "        rgt = self._read_vol(\"rgt\", file_id)\n",
    "        fault = self._read_vol(\"fault\", file_id)\n",
    "\n",
    "        if self.augment:\n",
    "            # 1) Random Horizontal Flip (left-right)\n",
    "            if random.random() > 0.5:\n",
    "                seis = np.flip(seis, axis=2).copy()\n",
    "                rgt = np.flip(rgt, axis=2).copy()\n",
    "                fault = np.flip(fault, axis=2).copy()\n",
    "\n",
    "            # 2) Random Vertical Flip (inline direction)\n",
    "            if random.random() > 0.5:\n",
    "                seis = np.flip(seis, axis=0).copy()\n",
    "                rgt = np.flip(rgt, axis=0).copy()\n",
    "                fault = np.flip(fault, axis=0).copy()\n",
    "\n",
    "            # 3) Random Rotation in spatial plane only (axes 1 & 2)\n",
    "            # Do NOT rotate time/depth axis (axis 0)\n",
    "            k = random.randint(0, 3)\n",
    "            if k > 0:\n",
    "                seis = np.rot90(seis, k=k, axes=(1, 2)).copy()\n",
    "                rgt = np.rot90(rgt, k=k, axes=(1, 2)).copy()\n",
    "                fault = np.rot90(fault, k=k, axes=(1, 2)).copy()\n",
    "\n",
    "        # normalize seismic and rgt by mean/std\n",
    "        seis = (seis - seis.mean()) / (seis.std() + 1e-8)\n",
    "        rgt = (rgt - rgt.mean()) / (rgt.std() + 1e-8)\n",
    "        fault = (fault > 0.5).astype(np.float32)\n",
    "\n",
    "        seis = np.ascontiguousarray(seis)\n",
    "        rgt = np.ascontiguousarray(rgt)\n",
    "        fault = np.ascontiguousarray(fault)\n",
    "\n",
    "        # (D,H,W) -> (1,W,H,D) to stay consistent with existing project ordering\n",
    "        seis_t = torch.from_numpy(np.transpose(seis[None, ...], (0, 3, 2, 1)).copy())\n",
    "        rgt_t = torch.from_numpy(np.transpose(rgt[None, ...], (0, 3, 2, 1)).copy())\n",
    "        fault_t = torch.from_numpy(np.transpose(fault[None, ...], (0, 3, 2, 1)).copy())\n",
    "\n",
    "        return seis_t.float(), rgt_t.float(), fault_t.float(), file_id\n",
    "\n",
    "\n",
    "train_ids, temp_ids = train_test_split(ids, test_size=(1.0 - CFG[\"train_ratio\"]), random_state=SEED, shuffle=True)\n",
    "val_rel = CFG[\"val_ratio\"] / (CFG[\"val_ratio\"] + CFG[\"test_ratio\"])\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=(1.0 - val_rel), random_state=SEED, shuffle=True)\n",
    "\n",
    "print(f\"Train/Val/Test = {len(train_ids)}/{len(val_ids)}/{len(test_ids)}\")\n",
    "\n",
    "train_ds = RgtFaultDataset(DATA_ROOT, train_ids, CFG[\"shape\"], augment=CFG[\"use_augmentation\"])\n",
    "val_ds = RgtFaultDataset(DATA_ROOT, val_ids, CFG[\"shape\"], augment=False)\n",
    "test_ds = RgtFaultDataset(DATA_ROOT, test_ids, CFG[\"shape\"], augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
    "                          num_workers=CFG[\"num_workers\"], pin_memory=CFG[\"pin_memory\"] and use_cuda)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False,\n",
    "                        num_workers=CFG[\"num_workers\"], pin_memory=CFG[\"pin_memory\"] and use_cuda)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False,\n",
    "                         num_workers=CFG[\"num_workers\"], pin_memory=CFG[\"pin_memory\"] and use_cuda)\n",
    "\n",
    "xb, y_rgt_b, y_fault_b, _ = next(iter(train_loader))\n",
    "print(\"Batch shapes:\", tuple(xb.shape), tuple(y_rgt_b.shape), tuple(y_fault_b.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa4e48",
   "metadata": {},
   "source": [
    "## 4) Define the Multitask Model (Shared Encoder, Two Heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskRgtFaultModel(nn.Module):\n",
    "    def __init__(self, pretrained_rgt_path=None):\n",
    "        super().__init__()\n",
    "        self.rgt_net = net3d.model({\n",
    "            \"input_channels\": 1,\n",
    "            \"encoder_channels\": 512,\n",
    "            \"decoder_channels\": 16,\n",
    "        })\n",
    "        self.fault_head = nn.Sequential(\n",
    "            nn.Conv3d(2, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(8, 1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "        if pretrained_rgt_path is not None:\n",
    "            ckpt = torch.load(pretrained_rgt_path, map_location=\"cpu\")\n",
    "            state = ckpt.get(\"model_state_dict\", ckpt)\n",
    "            cleaned_state = {}\n",
    "            for key, value in state.items():\n",
    "                nk = key[7:] if key.startswith(\"module.\") else key\n",
    "                if nk.startswith(\"rgt_net.\"):\n",
    "                    nk = nk[len(\"rgt_net.\"): ]\n",
    "                cleaned_state[nk] = value\n",
    "\n",
    "            missing, unexpected = self.rgt_net.load_state_dict(cleaned_state, strict=False)\n",
    "            print(f\"Loaded pretrained RGT weights from: {pretrained_rgt_path}\")\n",
    "            print(f\"Warm-start missing keys: {len(missing)}, unexpected keys: {len(unexpected)}\")\n",
    "\n",
    "    def forward(self, seis):\n",
    "        pred_rgt = self.rgt_net(seis)\n",
    "        fault_in = torch.cat([seis, pred_rgt], dim=1)\n",
    "        pred_fault_logits = self.fault_head(fault_in)\n",
    "        return pred_rgt, pred_fault_logits\n",
    "\n",
    "\n",
    "model = MultiTaskRgtFaultModel(pretrained_rgt_path=PRETRAINED_RGT_CKPT)\n",
    "if use_cuda:\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count())).to(device)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {n_params:,}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb = xb.to(device)\n",
    "    rgt_pred_b, fault_logit_b = model(xb)\n",
    "print(\"Forward sanity:\", tuple(rgt_pred_b.shape), tuple(fault_logit_b.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0e14c",
   "metadata": {},
   "source": [
    "## 5) Configure Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG[\"loss_rgt\"].upper() == \"SSIM\":\n",
    "    criterion_rgt = ssim3DLoss()\n",
    "else:\n",
    "    criterion_rgt = mse3DLoss()\n",
    "\n",
    "# estimate pos_weight from a few batches\n",
    "pos = 0.0\n",
    "neg = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (_, _, f, _) in enumerate(train_loader):\n",
    "        if i >= min(20, len(train_loader)):\n",
    "            break\n",
    "        pos += float((f > 0.5).sum().item())\n",
    "        neg += float((f <= 0.5).sum().item())\n",
    "pos_weight = torch.tensor([neg / max(pos, 1.0)], device=device)\n",
    "criterion_fault = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=CFG[\"lr_factor\"], patience=CFG[\"lr_patience\"])\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(use_cuda and CFG[\"mixed_precision\"]))\n",
    "\n",
    "print(\"RGT loss:\", criterion_rgt.getLossName())\n",
    "print(\"Fault loss: BCEWithLogitsLoss\")\n",
    "print(\"Fault pos_weight:\", float(pos_weight.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c759d",
   "metadata": {},
   "source": [
    "## 6) Training and Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_reg_meter():\n",
    "    return {\"abs_sum\": 0.0, \"sq_sum\": 0.0, \"count\": 0}\n",
    "\n",
    "\n",
    "def update_reg_meter(meter, y_true, y_pred):\n",
    "    diff = (y_true - y_pred).detach()\n",
    "    meter[\"abs_sum\"] += float(diff.abs().sum().item())\n",
    "    meter[\"sq_sum\"] += float((diff * diff).sum().item())\n",
    "    meter[\"count\"] += int(diff.numel())\n",
    "\n",
    "\n",
    "def finalize_reg_meter(meter):\n",
    "    if meter[\"count\"] == 0:\n",
    "        return np.nan, np.nan\n",
    "    mae = meter[\"abs_sum\"] / meter[\"count\"]\n",
    "    rmse = float(np.sqrt(meter[\"sq_sum\"] / meter[\"count\"]))\n",
    "    return float(mae), float(rmse)\n",
    "\n",
    "\n",
    "def compute_fault_stats(logits, target):\n",
    "    pred = (torch.sigmoid(logits) > 0.5).float()\n",
    "    tp = ((pred == 1) & (target == 1)).sum().item()\n",
    "    fp = ((pred == 1) & (target == 0)).sum().item()\n",
    "    fn = ((pred == 0) & (target == 1)).sum().item()\n",
    "    tn = ((pred == 0) & (target == 0)).sum().item()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "\n",
    "def summarize_fault(tp, fp, fn, tn):\n",
    "    precision = tp / max(tp + fp, 1)\n",
    "    recall = tp / max(tp + fn, 1)\n",
    "    f1 = 2 * precision * recall / max(precision + recall, 1e-8)\n",
    "    iou = tp / max(tp + fp + fn, 1)\n",
    "    acc = (tp + tn) / max(tp + fp + fn + tn, 1)\n",
    "    return dict(precision=precision, recall=recall, f1=f1, iou=iou, acc=acc)\n",
    "\n",
    "\n",
    "def run_epoch(loader, train_mode=True, epoch_idx=0, total_epochs=1):\n",
    "    if train_mode:\n",
    "        model.train()\n",
    "        title = \"Train\"\n",
    "    else:\n",
    "        model.eval()\n",
    "        title = \"Val\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0.0\n",
    "    total_rgt_loss = 0.0\n",
    "    total_fault_loss = 0.0\n",
    "\n",
    "    reg_meter = init_reg_meter()\n",
    "    tp = fp = fn = tn = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch_idx+1}/{total_epochs} [{title}]\", dynamic_ncols=True)\n",
    "\n",
    "    for bidx, (seis, rgt_gt, fault_gt, _) in enumerate(pbar):\n",
    "        seis = seis.to(device, non_blocking=True)\n",
    "        rgt_gt = rgt_gt.to(device, non_blocking=True)\n",
    "        fault_gt = fault_gt.to(device, non_blocking=True)\n",
    "\n",
    "        if train_mode:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=scaler.is_enabled()):\n",
    "                rgt_pred, fault_logits = model(seis)\n",
    "                rgt_loss = criterion_rgt(rgt_pred, rgt_gt)\n",
    "                fault_loss = criterion_fault(fault_logits, fault_gt)\n",
    "                loss = CFG[\"lambda_rgt\"] * rgt_loss + CFG[\"lambda_fault\"] * fault_loss\n",
    "\n",
    "            if train_mode:\n",
    "                try:\n",
    "                    scaler.scale(loss).backward()\n",
    "                except torch.cuda.OutOfMemoryError as e:\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    raise RuntimeError(\"CUDA OOM during backward. Reduce CFG['batch_size'], set CFG['loss_rgt']=MSE, or reduce CFG['max_samples'] for a smoke test.\") from e\n",
    "                if CFG[\"grad_clip\"] is not None:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        total_rgt_loss += float(rgt_loss.detach().cpu())\n",
    "        total_fault_loss += float(fault_loss.detach().cpu())\n",
    "\n",
    "        update_reg_meter(reg_meter, rgt_gt, rgt_pred)\n",
    "        ctp, cfp, cfn, ctn = compute_fault_stats(fault_logits.detach(), fault_gt.detach())\n",
    "        tp += ctp; fp += cfp; fn += cfn; tn += ctn\n",
    "\n",
    "        avg_loss = total_loss / (bidx + 1)\n",
    "        elapsed = time.time() - t0\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", rgt=f\"{(total_rgt_loss/(bidx+1)):.4f}\", fault=f\"{(total_fault_loss/(bidx+1)):.4f}\", lr=f\"{optimizer.param_groups[0]['lr']:.2e}\", sec=f\"{elapsed:.1f}\")\n",
    "\n",
    "    mean_loss = total_loss / max(len(loader), 1)\n",
    "    mean_rgt_loss = total_rgt_loss / max(len(loader), 1)\n",
    "    mean_fault_loss = total_fault_loss / max(len(loader), 1)\n",
    "\n",
    "    rgt_mae, rgt_rmse = finalize_reg_meter(reg_meter)\n",
    "\n",
    "    fstats = summarize_fault(tp, fp, fn, tn)\n",
    "\n",
    "    return {\n",
    "        \"loss\": mean_loss,\n",
    "        \"rgt_loss\": mean_rgt_loss,\n",
    "        \"fault_loss\": mean_fault_loss,\n",
    "        \"rgt_mae\": rgt_mae,\n",
    "        \"rgt_rmse\": rgt_rmse,\n",
    "        **fstats,\n",
    "        \"time_sec\": time.time() - t0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f8a8b",
   "metadata": {},
   "source": [
    "## 7) Train, Validate, and Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2775a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = -1\n",
    "best_ckpt = CKPT_PATH / \"best_rgt_fault.pth\"\n",
    "\n",
    "train_begin = time.time()\n",
    "for epoch in range(CFG[\"epochs\"]):\n",
    "    train_stats = run_epoch(train_loader, train_mode=True, epoch_idx=epoch, total_epochs=CFG[\"epochs\"])\n",
    "    val_stats = run_epoch(val_loader, train_mode=False, epoch_idx=epoch, total_epochs=CFG[\"epochs\"])\n",
    "\n",
    "    scheduler.step(val_stats[\"loss\"])\n",
    "    lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    row = {\n",
    "        \"epoch\": epoch,\n",
    "        \"lr\": lr_now,\n",
    "        \"train\": train_stats,\n",
    "        \"val\": val_stats,\n",
    "        \"elapsed_total_sec\": time.time() - train_begin,\n",
    "    }\n",
    "    history.append(row)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{CFG['epochs']} | \"\n",
    "        f\"train_loss={train_stats['loss']:.5f} val_loss={val_stats['loss']:.5f} | \"\n",
    "        f\"train_f1={train_stats['f1']:.4f} val_f1={val_stats['f1']:.4f} | \"\n",
    "        f\"train_rmse={train_stats['rgt_rmse']:.4f} val_rmse={val_stats['rgt_rmse']:.4f} | \"\n",
    "        f\"lr={lr_now:.2e}\"\n",
    "    )\n",
    "\n",
    "    save_obj = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"cfg\": CFG,\n",
    "        \"session_name\": SESSION_NAME,\n",
    "        \"history_tail\": history[-5:],\n",
    "    }\n",
    "\n",
    "    if val_stats[\"loss\"] < best_val:\n",
    "        best_val = val_stats[\"loss\"]\n",
    "        best_epoch = epoch\n",
    "        torch.save(save_obj, best_ckpt)\n",
    "        print(f\"  -> Saved BEST checkpoint: {best_ckpt}\")\n",
    "\n",
    "    if (epoch + 1) % CFG[\"save_every\"] == 0:\n",
    "        ep_ckpt = CKPT_PATH / f\"epoch_{epoch+1:04d}.pth\"\n",
    "        torch.save(save_obj, ep_ckpt)\n",
    "        print(f\"  -> Saved periodic checkpoint: {ep_ckpt}\")\n",
    "\n",
    "print(f\"Training finished. Best epoch={best_epoch+1}, best val loss={best_val:.6f}\")\n",
    "\n",
    "with open(HISTORY_PATH / \"history_rgt_fault.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "with open(HISTORY_PATH / \"run_info_rgt_fault.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"session_name\": SESSION_NAME,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_val_loss\": best_val,\n",
    "        \"best_checkpoint\": str(best_ckpt),\n",
    "        \"cfg\": CFG,\n",
    "        \"seed\": SEED,\n",
    "        \"device\": str(device),\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved history + run info in\", HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24de88",
   "metadata": {},
   "source": [
    "## 8) Final Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(best_ckpt, map_location=device)\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    model.module.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "else:\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "\n",
    "model.eval()\n",
    "test_stats = run_epoch(test_loader, train_mode=False, epoch_idx=0, total_epochs=1)\n",
    "print(\"Test metrics:\")\n",
    "print(json.dumps(test_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038b32e",
   "metadata": {},
   "source": [
    "## 9) 3Ã—5 Visualization Panel (Inline / Xline / Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices_3(v):\n",
    "    # v shape (D,H,W)\n",
    "    d, h, w = v.shape\n",
    "    return [v[d // 2, :, :], v[:, h // 2, :], v[:, :, w // 2]]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    seis_b, rgt_b, fault_b, ids_b = next(iter(test_loader))\n",
    "    seis_b = seis_b.to(device)\n",
    "    rgt_pred_b, fault_logit_b = model(seis_b)\n",
    "\n",
    "seis_v = seis_b[0, 0].detach().cpu().numpy()      # (W,H,D) due to transpose in dataset\n",
    "rgt_gt_v = rgt_b[0, 0].detach().cpu().numpy()\n",
    "rgt_pr_v = rgt_pred_b[0, 0].detach().cpu().numpy()\n",
    "fault_gt_v = fault_b[0, 0].detach().cpu().numpy()\n",
    "fault_pr_v = torch.sigmoid(fault_logit_b[0, 0]).detach().cpu().numpy()\n",
    "\n",
    "# bring back to (D,H,W) for display consistency\n",
    "seis_v = np.transpose(seis_v, (2, 1, 0))\n",
    "rgt_gt_v = np.transpose(rgt_gt_v, (2, 1, 0))\n",
    "rgt_pr_v = np.transpose(rgt_pr_v, (2, 1, 0))\n",
    "fault_gt_v = np.transpose(fault_gt_v, (2, 1, 0))\n",
    "fault_pr_v = np.transpose(fault_pr_v, (2, 1, 0))\n",
    "\n",
    "rows = [\n",
    "    (\"Mid Inline\", lambda v: slices_3(v)[0]),\n",
    "    (\"Mid Xline\", lambda v: slices_3(v)[1]),\n",
    "    (\"Mid Time\", lambda v: slices_3(v)[2]),\n",
    "]\n",
    "\n",
    "col_titles = [\"Seismic\", \"Fault GT\", \"Fault Pred\", \"RGT GT\", \"RGT Pred\"]\n",
    "vols = [seis_v, fault_gt_v, fault_pr_v, rgt_gt_v, rgt_pr_v]\n",
    "cmaps = [\"gray\", \"magma\", \"magma\", \"jet\", \"jet\"]\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(18, 10))\n",
    "for r, (row_name, row_fn) in enumerate(rows):\n",
    "    for c in range(5):\n",
    "        sl = row_fn(vols[c])\n",
    "        ax[r, c].imshow(sl, cmap=cmaps[c], aspect=\"auto\")\n",
    "        if r == 0:\n",
    "            ax[r, c].set_title(col_titles[c])\n",
    "        if c == 0:\n",
    "            ax[r, c].set_ylabel(row_name)\n",
    "        ax[r, c].axis(\"off\")\n",
    "\n",
    "sample_name = ids_b[0]\n",
    "plt.suptitle(f\"Sample: {sample_name}\", y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(FIG_PATH / f\"panel_3x5_{sample_name}.png\", dpi=150)\n",
    "print(\"Saved panel figure:\", FIG_PATH / f\"panel_3x5_{sample_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7944e",
   "metadata": {},
   "source": [
    "## 10) Minimal Inference Helper (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5628b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(file_id: str):\n",
    "    ds = RgtFaultDataset(DATA_ROOT, [file_id], CFG[\"shape\"])\n",
    "    seis_t, rgt_t, fault_t, _ = ds[0]\n",
    "    x = seis_t.unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pr_rgt, pr_fault_logit = model(x)\n",
    "    pr_fault = torch.sigmoid(pr_fault_logit)\n",
    "    return {\n",
    "        \"seis\": seis_t.numpy(),\n",
    "        \"rgt_gt\": rgt_t.numpy(),\n",
    "        \"fault_gt\": fault_t.numpy(),\n",
    "        \"rgt_pred\": pr_rgt[0].cpu().numpy(),\n",
    "        \"fault_pred\": pr_fault[0].cpu().numpy(),\n",
    "    }\n",
    "\n",
    "print(\"Use: out = predict_one(test_ids[0])\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
