{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc69d8d",
   "metadata": {},
   "source": [
    "# Train RGT-Only Model (Independent Pipeline)\n",
    "\n",
    "This notebook trains only the **RGT prediction model** (seismic ➜ RGT) and keeps it independent from any future fault+RGT multitask model.\n",
    "\n",
    "## What this notebook includes\n",
    "- GPU-first setup with explicit device message.\n",
    "- Dataset checks and sample inspection.\n",
    "- Train/validation/test splits and DataLoaders.\n",
    "- RGT model training with progress bars and timing.\n",
    "- Validation metrics and checkpointing.\n",
    "- Final test evaluation and reproducibility artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a75e4",
   "metadata": {},
   "source": [
    "## 1) Set Up Environment and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roderickperez/DataScienceProjects/RGT_Net/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU MODE] Training will run on: NVIDIA RTX A5000\n",
      "Session: /home/roderickperez/DataScienceProjects/RGT_Net/sessions/rgt_only_Feb18_125329_Train\n",
      "Data root: /home/roderickperez/DataScienceProjects/RGT_Net/datasets/syn\n",
      "Config:\n",
      "{\n",
      "  \"shape\": [\n",
      "    256,\n",
      "    256,\n",
      "    128\n",
      "  ],\n",
      "  \"n_channels\": 1,\n",
      "  \"batch_size\": 1,\n",
      "  \"epochs\": 400,\n",
      "  \"lr\": 0.0008,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"lr_factor\": 0.5,\n",
      "  \"lr_patience\": 2,\n",
      "  \"loss_type\": \"MSE\",\n",
      "  \"num_workers\": 2,\n",
      "  \"encoder_channels\": 512,\n",
      "  \"decoder_channels\": 16,\n",
      "  \"pin_memory\": true,\n",
      "  \"mixed_precision\": true,\n",
      "  \"grad_clip\": null,\n",
      "  \"train_ratio\": 0.8,\n",
      "  \"val_ratio\": 0.1,\n",
      "  \"test_ratio\": 0.1,\n",
      "  \"max_samples\": null,\n",
      "  \"save_every\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "from models import net3d\n",
    "from data.dataloader import Dataset\n",
    "from data.augments import Reshape, ToTensor\n",
    "from lossf.loss import mse3DLoss, ssim3DLoss\n",
    "from lossf.metrics import Result\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "DATA_ROOT = ROOT / \"datasets\" / \"syn\"\n",
    "SEIS_DIR = DATA_ROOT / \"seis\"\n",
    "RGT_DIR = DATA_ROOT / \"rgt\"\n",
    "\n",
    "session_name = f\"rgt_only_{datetime.now().strftime('%b%d_%H%M%S')}_Train\"\n",
    "session_path = ROOT / \"sessions\" / session_name\n",
    "checkpoint_path = session_path / \"checkpoint\"\n",
    "history_path = session_path / \"history\"\n",
    "picture_path = session_path / \"picture\"\n",
    "for p in [session_path, checkpoint_path, history_path, picture_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    # Paper-inspired defaults\n",
    "    \"shape\": (256, 256, 128),\n",
    "    \"n_channels\": 1,\n",
    "    \"batch_size\": 1,\n",
    "    \"epochs\": 400,\n",
    "    \"lr\": 8e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 2,\n",
    "    \"loss_type\": \"SSIM\",  # 'SSIM' or 'MSE'\n",
    "\n",
    "    # Runtime\n",
    "    \"num_workers\": 2,\n",
    "    \"encoder_channels\": 512,\n",
    "    \"decoder_channels\": 16,\n",
    "    \"pin_memory\": True,\n",
    "    \"mixed_precision\": True,\n",
    "    \"grad_clip\": None,\n",
    "\n",
    "    # Splits\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "\n",
    "    # Optional cap for quick tests\n",
    "    \"max_samples\": None,\n",
    "    \"use_augmentation\": True,\n",
    "\n",
    "    # Save intervals\n",
    "    \"save_every\": 10,\n",
    "}\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print(f\"[GPU MODE] Training will run on: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[CPU MODE] CUDA not available. Training will run on CPU.\")\n",
    "\n",
    "print(\"Session:\", session_path)\n",
    "print(\"Data root:\", DATA_ROOT)\n",
    "print(\"Config:\")\n",
    "print(json.dumps(CFG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459959c",
   "metadata": {},
   "source": [
    "## 2) Load and Inspect RGT-Only Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23413ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seis files: 500\n",
      "RGT files:  500\n",
      "Matched pairs: 500\n",
      "Using sample count: 500\n",
      "Random sample: 393.dat\n",
      "Seis stats  min/max/mean/std: -7.617023944854736 8.524500846862793 0.0018466644687578082 1.166604995727539\n",
      "RGT stats   min/max/mean/std: 19.889814376831055 170.3407745361328 91.55370330810547 30.695148468017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18891/298694095.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "assert SEIS_DIR.exists(), f\"Missing seismic directory: {SEIS_DIR}\"\n",
    "assert RGT_DIR.exists(), f\"Missing RGT directory: {RGT_DIR}\"\n",
    "\n",
    "seis_files = sorted([f.name for f in SEIS_DIR.iterdir() if f.is_file()])\n",
    "rgt_files = sorted([f.name for f in RGT_DIR.iterdir() if f.is_file()])\n",
    "common_files = sorted(list(set(seis_files).intersection(set(rgt_files))))\n",
    "\n",
    "print(f\"Seis files: {len(seis_files)}\")\n",
    "print(f\"RGT files:  {len(rgt_files)}\")\n",
    "print(f\"Matched pairs: {len(common_files)}\")\n",
    "\n",
    "missing_in_rgt = sorted(list(set(seis_files) - set(rgt_files)))\n",
    "missing_in_seis = sorted(list(set(rgt_files) - set(seis_files)))\n",
    "if missing_in_rgt:\n",
    "    print(f\"Warning: {len(missing_in_rgt)} seismic files missing in rgt\")\n",
    "if missing_in_seis:\n",
    "    print(f\"Warning: {len(missing_in_seis)} rgt files missing in seis\")\n",
    "\n",
    "if CFG[\"max_samples\"] is not None:\n",
    "    common_files = common_files[:CFG[\"max_samples\"]]\n",
    "\n",
    "print(\"Using sample count:\", len(common_files))\n",
    "\n",
    "# Quick sample stats\n",
    "n1, n2, n3 = CFG[\"shape\"]\n",
    "sample_id = random.choice(common_files)\n",
    "seis_raw = np.fromfile(SEIS_DIR / sample_id, dtype=np.float32).reshape((n1, n2, n3, CFG[\"n_channels\"]))[..., 0]\n",
    "rgt_raw = np.fromfile(RGT_DIR / sample_id, dtype=np.float32).reshape((n1, n2, n3, CFG[\"n_channels\"]))[..., 0]\n",
    "\n",
    "print(\"Random sample:\", sample_id)\n",
    "print(\"Seis stats  min/max/mean/std:\", float(seis_raw.min()), float(seis_raw.max()), float(seis_raw.mean()), float(seis_raw.std()))\n",
    "print(\"RGT stats   min/max/mean/std:\", float(rgt_raw.min()), float(rgt_raw.max()), float(rgt_raw.mean()), float(rgt_raw.std()))\n",
    "\n",
    "mid_i, mid_x, mid_t = n1 // 2, n2 // 2, n3 // 2\n",
    "fig, ax = plt.subplots(2, 3, figsize=(14, 8))\n",
    "ax[0, 0].imshow(seis_raw[mid_i, :, :], cmap=\"gray\", aspect=\"auto\"); ax[0, 0].set_title(\"Seis Inline(mid)\")\n",
    "ax[0, 1].imshow(seis_raw[:, mid_x, :], cmap=\"gray\", aspect=\"auto\"); ax[0, 1].set_title(\"Seis Xline(mid)\")\n",
    "ax[0, 2].imshow(seis_raw[:, :, mid_t], cmap=\"gray\", aspect=\"auto\"); ax[0, 2].set_title(\"Seis Time(mid)\")\n",
    "ax[1, 0].imshow(rgt_raw[mid_i, :, :], cmap=\"jet\", aspect=\"auto\"); ax[1, 0].set_title(\"RGT Inline(mid)\")\n",
    "ax[1, 1].imshow(rgt_raw[:, mid_x, :], cmap=\"jet\", aspect=\"auto\"); ax[1, 1].set_title(\"RGT Xline(mid)\")\n",
    "ax[1, 2].imshow(rgt_raw[:, :, mid_t], cmap=\"jet\", aspect=\"auto\"); ax[1, 2].set_title(\"RGT Time(mid)\")\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea3c1f",
   "metadata": {},
   "source": [
    "## 3) Build Dataset and DataLoader Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f18c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test: 400/50/50\n",
      "DataLoaders ready. Train batches: 400, Val batches: 50, Test batches: 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_ids = common_files.copy()\n",
    "\n",
    "train_ratio = CFG[\"train_ratio\"]\n",
    "val_ratio = CFG[\"val_ratio\"]\n",
    "test_ratio = CFG[\"test_ratio\"]\n",
    "assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-8, \"Ratios must sum to 1.0\"\n",
    "\n",
    "train_ids, temp_ids = train_test_split(all_ids, test_size=(1.0 - train_ratio), random_state=SEED, shuffle=True)\n",
    "val_rel = val_ratio / (val_ratio + test_ratio)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=(1.0 - val_rel), random_state=SEED, shuffle=True)\n",
    "\n",
    "print(f\"Train/Val/Test: {len(train_ids)}/{len(val_ids)}/{len(test_ids)}\")\n",
    "\n",
    "class AugmentedPairDataset:\n",
    "    def __init__(self, base_ds, augment=False):\n",
    "        self.base_ds = base_ds\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.base_ds[index]\n",
    "        if self.augment:\n",
    "            # shape is (C, D, H, W); protect D (depth/time)\n",
    "            # Random flips on spatial axes only (H, W)\n",
    "            if random.random() < 0.5:\n",
    "                x = torch.flip(x, dims=[2])\n",
    "                y = torch.flip(y, dims=[2])\n",
    "            if random.random() < 0.5:\n",
    "                x = torch.flip(x, dims=[3])\n",
    "                y = torch.flip(y, dims=[3])\n",
    "\n",
    "            # Random 90-degree in-plane rotation (H, W)\n",
    "            k = random.randint(0, 3)\n",
    "            if k > 0:\n",
    "                x = torch.rot90(x, k=k, dims=(2, 3))\n",
    "                y = torch.rot90(y, k=k, dims=(2, 3))\n",
    "\n",
    "        return x.contiguous(), y.contiguous()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Reshape((CFG[\"shape\"][0], CFG[\"shape\"][1], CFG[\"shape\"][2], CFG[\"n_channels\"])),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "train_base_ds = Dataset(root_dir=str(DATA_ROOT), list_IDs=train_ids, transform=transform, only_load_input=False)\n",
    "val_ds = Dataset(root_dir=str(DATA_ROOT), list_IDs=val_ids, transform=transform, only_load_input=False)\n",
    "test_ds = Dataset(root_dir=str(DATA_ROOT), list_IDs=test_ids, transform=transform, only_load_input=False)\n",
    "train_ds = AugmentedPairDataset(train_base_ds, augment=CFG[\"use_augmentation\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=CFG[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=CFG[\"num_workers\"],\n",
    "    pin_memory=CFG[\"pin_memory\"] and use_cuda,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG[\"num_workers\"],\n",
    "    pin_memory=CFG[\"pin_memory\"] and use_cuda,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG[\"num_workers\"],\n",
    "    pin_memory=CFG[\"pin_memory\"] and use_cuda,\n",
    ")\n",
    "\n",
    "print(f\"DataLoaders ready. Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245c522",
   "metadata": {},
   "source": [
    "## 4) Define the RGT Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a01a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: total=56,641,012, trainable=56,641,012\n",
      "Input shape: (1, 1, 128, 256, 256) Pred shape: (1, 1, 128, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "param_model = {\n",
    "    \"input_channels\": 1,\n",
    "    \"encoder_channels\": 512,\n",
    "    \"decoder_channels\": 16,\n",
    "}\n",
    "model = net3d.model(param_model)\n",
    "\n",
    "if use_cuda:\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(num_gpu)).to(device)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model parameters: total={num_params:,}, trainable={num_trainable:,}\")\n",
    "\n",
    "# Forward sanity check\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb = xb.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(xb)\n",
    "print(\"Input shape:\", tuple(xb.shape), \"Pred shape:\", tuple(pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd37b9e",
   "metadata": {},
   "source": [
    "## 5) Configure Loss, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e279f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: MSE\n",
      "Optimizer: Adam(lr=0.0008, weight_decay=0.0001)\n",
      "Scheduler: ReduceLROnPlateau(factor=0.5, patience=2)\n",
      "Mixed precision enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18891/1312312647.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_cuda and CFG[\"mixed_precision\"]))\n"
     ]
    }
   ],
   "source": [
    "if CFG[\"loss_type\"].upper() == \"SSIM\":\n",
    "    criterion = ssim3DLoss()\n",
    "else:\n",
    "    criterion = mse3DLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=CFG[\"lr_factor\"],\n",
    "    patience=CFG[\"lr_patience\"],\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(use_cuda and CFG[\"mixed_precision\"]))\n",
    "\n",
    "print(f\"Loss: {criterion.getLossName()}\")\n",
    "print(f\"Optimizer: Adam(lr={CFG['lr']}, weight_decay={CFG['weight_decay']})\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau(factor={CFG['lr_factor']}, patience={CFG['lr_patience']})\")\n",
    "print(f\"Mixed precision enabled: {scaler.is_enabled()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fbee2",
   "metadata": {},
   "source": [
    "## 6) Implement the RGT Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a875396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_regression_meter():\n",
    "    return {\"abs_sum\": 0.0, \"sq_sum\": 0.0, \"count\": 0}\n",
    "\n",
    "\n",
    "def update_regression_meter(meter, y_true, y_pred):\n",
    "    diff = (y_true - y_pred).detach()\n",
    "    meter[\"abs_sum\"] += float(diff.abs().sum().item())\n",
    "    meter[\"sq_sum\"] += float((diff * diff).sum().item())\n",
    "    meter[\"count\"] += int(diff.numel())\n",
    "\n",
    "\n",
    "def finalize_regression_meter(meter):\n",
    "    if meter[\"count\"] == 0:\n",
    "        return {\"mae\": np.nan, \"rmse\": np.nan}\n",
    "    mae = meter[\"abs_sum\"] / meter[\"count\"]\n",
    "    rmse = float(np.sqrt(meter[\"sq_sum\"] / meter[\"count\"]))\n",
    "    return {\"mae\": float(mae), \"rmse\": float(rmse)}\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device, epoch_idx, total_epochs):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    meter = init_regression_meter()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch_idx+1}/{total_epochs} [Train]\", dynamic_ncols=True)\n",
    "    for batch_idx, (seis, rgt) in enumerate(pbar):\n",
    "        seis = seis.to(device, non_blocking=True)\n",
    "        rgt = rgt.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=scaler.is_enabled()):\n",
    "            pred = model(seis)\n",
    "            loss = criterion(pred, rgt)\n",
    "\n",
    "        try:\n",
    "            scaler.scale(loss).backward()\n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            raise RuntimeError(\"CUDA OOM during backward. Reduce CFG['batch_size'], switch CFG['loss_type'] to 'MSE', or reduce CFG['max_samples'] for a smoke test.\") from e\n",
    "\n",
    "        if CFG[\"grad_clip\"] is not None:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_value = float(loss.detach().cpu())\n",
    "        running_loss += loss_value\n",
    "\n",
    "        update_regression_meter(meter, rgt, pred)\n",
    "\n",
    "        avg_loss = running_loss / (batch_idx + 1)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        elapsed = time.time() - t0\n",
    "        pbar.set_postfix(loss=f\"{loss_value:.4f}\", avg=f\"{avg_loss:.4f}\", lr=f\"{current_lr:.2e}\", sec=f\"{elapsed:.1f}\")\n",
    "\n",
    "    epoch_loss = running_loss / max(len(loader), 1)\n",
    "    metrics = finalize_regression_meter(meter)\n",
    "    metrics[\"loss\"] = float(epoch_loss)\n",
    "    metrics[\"time_sec\"] = float(time.time() - t0)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device, epoch_idx, total_epochs):\n",
    "    model.eval()\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    meter = init_regression_meter()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch_idx+1}/{total_epochs} [Val]\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (seis, rgt) in enumerate(pbar):\n",
    "            seis = seis.to(device, non_blocking=True)\n",
    "            rgt = rgt.to(device, non_blocking=True)\n",
    "\n",
    "            pred = model(seis)\n",
    "            loss = criterion(pred, rgt)\n",
    "\n",
    "            loss_value = float(loss.detach().cpu())\n",
    "            running_loss += loss_value\n",
    "\n",
    "            update_regression_meter(meter, rgt, pred)\n",
    "\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            elapsed = time.time() - t0\n",
    "            pbar.set_postfix(loss=f\"{loss_value:.4f}\", avg=f\"{avg_loss:.4f}\", sec=f\"{elapsed:.1f}\")\n",
    "\n",
    "    epoch_loss = running_loss / max(len(loader), 1)\n",
    "    metrics = finalize_regression_meter(meter)\n",
    "    metrics[\"loss\"] = float(epoch_loss)\n",
    "    metrics[\"time_sec\"] = float(time.time() - t0)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390f32c",
   "metadata": {},
   "source": [
    "## 7) Run Validation and Track Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d79382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/400 [Train]: 100%|██████████| 400/400 [15:54<00:00,  2.39s/it, avg=0.2835, loss=0.0648, lr=8.00e-04, sec=954.6]\n",
      "Epoch 1/400 [Val]: 100%|██████████| 50/50 [01:15<00:00,  1.50s/it, avg=0.2863, loss=0.2925, sec=75.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400 | train_loss=0.28349, val_loss=0.28635, train_rmse=0.53244, val_rmse=0.53511, lr=8.00e-04, epoch_time=1029.8s\n",
      "  -> Saved new best checkpoint: /home/roderickperez/DataScienceProjects/RGT_Net/sessions/rgt_only_Feb18_125329_Train/checkpoint/best_rgt_only.pth (val_loss=0.286348)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/400 [Train]: 100%|██████████| 400/400 [16:32<00:00,  2.48s/it, avg=0.2424, loss=0.1486, lr=8.00e-04, sec=992.7]\n",
      "Epoch 2/400 [Val]: 100%|██████████| 50/50 [01:15<00:00,  1.50s/it, avg=0.2489, loss=0.2380, sec=75.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/400 | train_loss=0.24236, val_loss=0.24887, train_rmse=0.49230, val_rmse=0.49887, lr=8.00e-04, epoch_time=1068.0s\n",
      "  -> Saved new best checkpoint: /home/roderickperez/DataScienceProjects/RGT_Net/sessions/rgt_only_Feb18_125329_Train/checkpoint/best_rgt_only.pth (val_loss=0.248875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/400 [Train]: 100%|██████████| 400/400 [16:52<00:00,  2.53s/it, avg=0.2313, loss=0.2503, lr=8.00e-04, sec=1012.3]\n",
      "Epoch 3/400 [Val]: 100%|██████████| 50/50 [01:14<00:00,  1.49s/it, avg=0.2533, loss=0.3748, sec=74.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/400 | train_loss=0.23126, val_loss=0.25330, train_rmse=0.48090, val_rmse=0.50329, lr=8.00e-04, epoch_time=1087.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/400 [Train]:  18%|█▊        | 71/400 [03:04<14:13,  2.59s/it, avg=0.1939, loss=0.2761, lr=8.00e-04, sec=181.5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m train_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m----> 8\u001b[0m     train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     val_stats \u001b[38;5;241m=\u001b[39m validate_one_epoch(model, val_loader, criterion, device, epoch, CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, scaler, device, epoch_idx, total_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m     46\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_clip\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 48\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     51\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/DataScienceProjects/RGT_Net/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/DataScienceProjects/RGT_Net/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/DataScienceProjects/RGT_Net/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "best_ckpt_path = checkpoint_path / \"best_rgt_only.pth\"\n",
    "\n",
    "train_start = time.time()\n",
    "for epoch in range(CFG[\"epochs\"]):\n",
    "    train_stats = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, epoch, CFG[\"epochs\"])\n",
    "    val_stats = validate_one_epoch(model, val_loader, criterion, device, epoch, CFG[\"epochs\"])\n",
    "\n",
    "    scheduler.step(val_stats[\"loss\"])\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    row = {\n",
    "        \"epoch\": epoch,\n",
    "        \"lr\": current_lr,\n",
    "        \"train_loss\": train_stats[\"loss\"],\n",
    "        \"train_mae\": train_stats[\"mae\"],\n",
    "        \"train_rmse\": train_stats[\"rmse\"],\n",
    "        \"val_loss\": val_stats[\"loss\"],\n",
    "        \"val_mae\": val_stats[\"mae\"],\n",
    "        \"val_rmse\": val_stats[\"rmse\"],\n",
    "        \"train_time_sec\": train_stats[\"time_sec\"],\n",
    "        \"val_time_sec\": val_stats[\"time_sec\"],\n",
    "        \"elapsed_total_sec\": time.time() - train_start,\n",
    "    }\n",
    "    history.append(row)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{CFG['epochs']} | \"\n",
    "        f\"train_loss={row['train_loss']:.5f}, val_loss={row['val_loss']:.5f}, \"\n",
    "        f\"train_rmse={row['train_rmse']:.5f}, val_rmse={row['val_rmse']:.5f}, \"\n",
    "        f\"lr={row['lr']:.2e}, epoch_time={(row['train_time_sec'] + row['val_time_sec']):.1f}s\"\n",
    "    )\n",
    "\n",
    "    if row[\"val_loss\"] < best_val_loss:\n",
    "        best_val_loss = row[\"val_loss\"]\n",
    "        best_epoch = epoch\n",
    "        save_obj = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"scaler_state_dict\": scaler.state_dict(),\n",
    "            \"config\": CFG,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"session_name\": session_name,\n",
    "        }\n",
    "        torch.save(save_obj, best_ckpt_path)\n",
    "        print(f\"  -> Saved new best checkpoint: {best_ckpt_path} (val_loss={best_val_loss:.6f})\")\n",
    "\n",
    "    if (epoch + 1) % CFG[\"save_every\"] == 0:\n",
    "        latest_ckpt_path = checkpoint_path / f\"epoch_{epoch+1:04d}.pth\"\n",
    "        save_obj = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"scaler_state_dict\": scaler.state_dict(),\n",
    "            \"config\": CFG,\n",
    "            \"session_name\": session_name,\n",
    "        }\n",
    "        torch.save(save_obj, latest_ckpt_path)\n",
    "        print(f\"  -> Saved periodic checkpoint: {latest_ckpt_path}\")\n",
    "\n",
    "print(f\"Training complete. Best epoch: {best_epoch+1}, best val_loss={best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbc270",
   "metadata": {},
   "source": [
    "## 8) Save Best Checkpoints and Training Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b902c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file = history_path / \"train_history_rgt_only.json\"\n",
    "with open(history_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "run_info = {\n",
    "    \"session_name\": session_name,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"best_val_loss\": best_val_loss,\n",
    "    \"best_checkpoint\": str(best_ckpt_path),\n",
    "    \"config\": CFG,\n",
    "    \"seed\": SEED,\n",
    "    \"device\": str(device),\n",
    "}\n",
    "run_info_file = history_path / \"run_info_rgt_only.json\"\n",
    "with open(run_info_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(run_info, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", history_file)\n",
    "print(\" -\", run_info_file)\n",
    "print(\" -\", best_ckpt_path)\n",
    "\n",
    "# Quick curves\n",
    "if len(history) > 0:\n",
    "    tr_loss = [x[\"train_loss\"] for x in history]\n",
    "    va_loss = [x[\"val_loss\"] for x in history]\n",
    "    tr_rmse = [x[\"train_rmse\"] for x in history]\n",
    "    va_rmse = [x[\"val_rmse\"] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax[0].plot(tr_loss, label=\"train\")\n",
    "    ax[0].plot(va_loss, label=\"val\")\n",
    "    ax[0].set_title(\"Loss\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(tr_rmse, label=\"train\")\n",
    "    ax[1].plot(va_rmse, label=\"val\")\n",
    "    ax[1].set_title(\"RMSE\")\n",
    "    ax[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddde95e",
   "metadata": {},
   "source": [
    "## 9) Evaluate the Trained RGT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(best_ckpt_path, map_location=device)\n",
    "state = ckpt[\"model_state_dict\"]\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    model.module.load_state_dict(state)\n",
    "else:\n",
    "    model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "y_true_list, y_pred_list = [], []\n",
    "worst_cases = []  # (abs_err_mean, seis, rgt, pred)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seis, rgt in tqdm(test_loader, desc=\"Test\", dynamic_ncols=True):\n",
    "        seis = seis.to(device)\n",
    "        rgt = rgt.to(device)\n",
    "        pred = model(seis)\n",
    "        loss = criterion(pred, rgt)\n",
    "\n",
    "        test_loss += float(loss.detach().cpu())\n",
    "        y_true_np = rgt.detach().cpu().numpy()\n",
    "        y_pred_np = pred.detach().cpu().numpy()\n",
    "        y_true_list.append(y_true_np)\n",
    "        y_pred_list.append(y_pred_np)\n",
    "\n",
    "        abs_err = float(np.mean(np.abs(y_true_np - y_pred_np)))\n",
    "        worst_cases.append((abs_err, seis.detach().cpu().numpy(), y_true_np, y_pred_np))\n",
    "\n",
    "mean_test_loss = test_loss / max(len(test_loader), 1)\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "test_mae = float(np.mean(np.abs(y_true - y_pred)))\n",
    "test_rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "print(f\"Test loss: {mean_test_loss:.6f}\")\n",
    "print(f\"Test MAE:  {test_mae:.6f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.6f}\")\n",
    "\n",
    "# For regression, confusion matrix is not standard; show a simple binned confusion table instead.\n",
    "y_true = y_true.ravel()\n",
    "y_pred = y_pred.ravel()\n",
    "num_bins = 10\n",
    "bins = np.linspace(min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max()), num_bins + 1)\n",
    "true_bin = np.clip(np.digitize(y_true, bins) - 1, 0, num_bins - 1)\n",
    "pred_bin = np.clip(np.digitize(y_pred, bins) - 1, 0, num_bins - 1)\n",
    "conf = np.zeros((num_bins, num_bins), dtype=np.int64)\n",
    "for t, p in zip(true_bin, pred_bin):\n",
    "    conf[t, p] += 1\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(conf, cmap=\"magma\", aspect=\"auto\")\n",
    "plt.title(\"Binned RGT Confusion Table (Regression Proxy)\")\n",
    "plt.xlabel(\"Predicted bin\")\n",
    "plt.ylabel(\"True bin\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Inspect top-3 worst cases\n",
    "worst_cases = sorted(worst_cases, key=lambda x: x[0], reverse=True)[:3]\n",
    "for i, (err, seis_np, rgt_np, pred_np) in enumerate(worst_cases, 1):\n",
    "    seis_v = seis_np[0, 0]   # (D, H, W)\n",
    "    rgt_v = rgt_np[0, 0]\n",
    "    pred_v = pred_np[0, 0]\n",
    "    mid_d = seis_v.shape[0] // 2\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(13, 4))\n",
    "    ax[0].imshow(seis_v[mid_d], cmap=\"gray\", aspect=\"auto\"); ax[0].set_title(f\"Worst #{i} Seis\")\n",
    "    ax[1].imshow(rgt_v[mid_d], cmap=\"jet\", aspect=\"auto\"); ax[1].set_title(\"GT RGT\")\n",
    "    ax[2].imshow(pred_v[mid_d], cmap=\"jet\", aspect=\"auto\"); ax[2].set_title(f\"Pred RGT (abs err {err:.4f})\")\n",
    "    for a in ax:\n",
    "        a.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1274558",
   "metadata": {},
   "source": [
    "## 10) Export RGT Inference Script and Reproducibility Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_script = ROOT / \"infer_rgt_only_from_notebook.py\"\n",
    "inference_script.write_text(\n",
    "'''import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import net3d\n",
    "from data.dataloader import Dataset\n",
    "from data.augments import Reshape, ToTensor\n",
    "\n",
    "ROOT = os.path.abspath(\".\")\n",
    "DATA_ROOT = os.path.join(ROOT, \"datasets\", \"syn\")\n",
    "CKPT = os.path.join(ROOT, \"sessions\", \"''' + session_name + '''\", \"checkpoint\", \"best_rgt_only.pth\")\n",
    "\n",
    "shape = (256, 256, 128)\n",
    "n_channels = 1\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data_list = sorted(os.listdir(os.path.join(DATA_ROOT, \"seis\")))\n",
    "    transform = transforms.Compose([Reshape((shape[0], shape[1], shape[2], n_channels)), ToTensor()])\n",
    "    ds = Dataset(root_dir=DATA_ROOT, list_IDs=data_list, transform=transform, only_load_input=True)\n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = net3d.model({\"input_channels\":1, \"encoder_channels\":512, \"decoder_channels\":16})\n",
    "    ckpt = torch.load(CKPT, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = next(iter(dl)).to(device)\n",
    "        pred = model(x)\n",
    "    print(\"Inference OK. Pred shape:\", tuple(pred.shape))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "''',\n",
    "encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "repro = {\n",
    "    \"session_name\": session_name,\n",
    "    \"best_checkpoint\": str(best_ckpt_path),\n",
    "    \"seed\": SEED,\n",
    "    \"config\": CFG,\n",
    "    \"torch_version\": torch.__version__,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"cuda_device_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "}\n",
    "with open(history_path / \"reproducibility_rgt_only.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(repro, f, indent=2)\n",
    "\n",
    "print(\"Exported inference script:\", inference_script)\n",
    "print(\"Saved reproducibility metadata:\", history_path / \"reproducibility_rgt_only.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
